{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8e24cb",
   "metadata": {},
   "source": [
    "# AI Translation Evaluation Pipeline\n",
    "\n",
    "This notebook evaluates machine translation outputs produced by multiple **AI models** across a set of `.txt` files.  \n",
    "It performs:\n",
    "\n",
    "1. **Data ingestion & parsing** of each `.txt` file (splitting source vs. model output).\n",
    "2. **Hypothesis/source preparation** by writing concatenated `src.txt` and `hypX.txt` files per model.\n",
    "3. **Quality Estimation (QE)** using a reference-free COMET QE model for each file.\n",
    "4. **Statistical testing** (paired t‑tests) to compare model scores across hypotheses.\n",
    "\n",
    "> Notes:\n",
    "> - The code is generalized to **AI models** (no vendor-specific names).\n",
    "> - File/folder structure is auto‑detected from a base directory that contains one subfolder per AI model.\n",
    "> - Each model subfolder is expected to contain `.txt` files with a *Source* and an *Output* section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c32a14",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c197643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on Google Colab, mount Drive once. Safe to skip on local environments.\n",
    "try:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    drive.mount('/content/drive')\n",
    "    BASE_DIR = \"/content/drive/MyDrive/AI\"  # <-- Set your base directory here\n",
    "else:\n",
    "    # Fallback: use a local path when not on Colab\n",
    "    BASE_DIR = \"./AI\"  # <-- Set your local base directory here\n",
    "\n",
    "print(\"IN_COLAB:\", IN_COLAB)\n",
    "print(\"BASE_DIR:\", BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a142dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if running on Colab\n",
    "if IN_COLAB:\n",
    "    !pip install -q unbabel-comet\n",
    "\n",
    "else :\n",
    "    %pip install -q unbabel-comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from typing import  Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ea9c2",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fe051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure patterns for parsing, expected file suffix, and naming rules.\n",
    "PARSE_KEYS = [\"Output:\", \"output:\"]  # Split marker between source and model output\n",
    "TXT_SUFFIX = \".txt\"\n",
    "\n",
    "# Optional: map each model folder to a human-readable hypothesis label.\n",
    "# By default, labels are inferred as hyp1, hyp2, ... in alphabetical order of folders.\n",
    "HYP_LABELS = {}  # e.g., {\"ModelA\": \"hyp1\", \"ModelB\": \"hyp2\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf8139",
   "metadata": {},
   "source": [
    "## 3. Discover Model Folders & Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15a16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_model_dir(path: str) -> bool:\n",
    "    # Heuristic: a model folder is a directory with at least one .txt file\n",
    "    if not os.path.isdir(path):\n",
    "        return False\n",
    "    files = [f for f in os.listdir(path) if f.endswith(TXT_SUFFIX)]\n",
    "    return len(files) > 0\n",
    "\n",
    "model_dirs = sorted([os.path.join(BASE_DIR, d) for d in os.listdir(BASE_DIR) if is_model_dir(os.path.join(BASE_DIR, d))])\n",
    "if not model_dirs:\n",
    "    raise RuntimeError(f\"No model directories with {TXT_SUFFIX} files found under {BASE_DIR}.\")\n",
    "\n",
    "print(\"Discovered model folders (alphabetical):\")\n",
    "for d in model_dirs:\n",
    "    print(\" -\", os.path.basename(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04378817",
   "metadata": {},
   "source": [
    "## 4. Parse .txt Files (Source vs. Hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945de55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_source_hyp(text: str, keys=PARSE_KEYS) -> Tuple[str, str]:\n",
    "    \"\"\"Split a file into (source, hypothesis) using the first matching key.\n",
    "    If no key is found, returns (text, \"\").\n",
    "    \"\"\"\n",
    "    for k in keys:\n",
    "        if k in text:\n",
    "            parts = text.split(k, 1)\n",
    "            return parts[0].strip(), parts[1].strip()\n",
    "    return text.strip(), \"\"\n",
    "\n",
    "# Build an index of files per model with extracted (src, hyp)\n",
    "corpus = {}\n",
    "for mdir in model_dirs:\n",
    "    model_name = os.path.basename(mdir)\n",
    "    files = sorted([f for f in os.listdir(mdir) if f.endswith(TXT_SUFFIX)])\n",
    "    entries = []\n",
    "    for f in files:\n",
    "        with open(os.path.join(mdir, f), 'r', encoding='utf-8', errors='ignore') as fh:\n",
    "            raw = fh.read()\n",
    "        src, hyp = split_source_hyp(raw)\n",
    "        entries.append({\"file\": f, \"source\": src, \"hypothesis\": hyp})\n",
    "    corpus[model_name] = entries\n",
    "\n",
    "# Quick sanity check\n",
    "print(\"Models parsed:\", list(corpus.keys()))\n",
    "for k, v in corpus.items():\n",
    "    print(f\"{k}: {len(v)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fea5910",
   "metadata": {},
   "source": [
    "## 5. Prepare `src.txt` and `hypX.txt` per Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ab78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine hypothesis labels in a stable order\n",
    "labels = {}\n",
    "for i, mdir in enumerate(model_dirs, start=1):\n",
    "    mname = os.path.basename(mdir)\n",
    "    labels[mname] = HYP_LABELS.get(mname, f\"hyp{i}\")\n",
    "\n",
    "# Create concatenated files inside each model directory\n",
    "for mdir in model_dirs:\n",
    "    mname = os.path.basename(mdir)\n",
    "    hyp_label = labels[mname]\n",
    "    src_out = os.path.join(mdir, \"src.txt\")\n",
    "    hyp_out = os.path.join(mdir, f\"{hyp_label}.txt\")\n",
    "\n",
    "    with open(src_out, \"w\", encoding=\"utf-8\") as fsrc, open(hyp_out, \"w\", encoding=\"utf-8\") as fhyp:\n",
    "        for rec in corpus[mname]:\n",
    "            # Each record appended as a single line; adjust joining if multi-line sentence granularity is desired\n",
    "            fsrc.write(rec[\"source\"].replace(\"\\n\", \" \").strip() + \"\\n\")\n",
    "            fhyp.write(rec[\"hypothesis\"].replace(\"\\n\", \" \").strip() + \"\\n\")\n",
    "\n",
    "    print(f\"Wrote: {src_out} and {hyp_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f885f08a",
   "metadata": {},
   "source": [
    "## 6. Load QE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference-free Quality Estimation (QE) model selection.\n",
    "# Using a widely adopted QE checkpoint intended for sentence-level evaluation.\n",
    "qe_model_path = download_model(\"wmt21-comet-qe-mqm\")\n",
    "qe_model = load_from_checkpoint(qe_model_path)\n",
    "print(\"Loaded QE model from:\", qe_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82f11ec",
   "metadata": {},
   "source": [
    "## 7. Score Files with QE (per Model, per File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31575c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for mdir in model_dirs:\n",
    "    mname = os.path.basename(mdir)\n",
    "    for rec in corpus[mname]:\n",
    "        src = rec[\"source\"]\n",
    "        hyp = rec[\"hypothesis\"]\n",
    "        # Build a single-sentence sample for QE (reference-free)\n",
    "        data = [{\"src\": src, \"mt\": hyp}]\n",
    "        try:\n",
    "            output = qe_model.predict(data, batch_size=8, gpus=0)\n",
    "            score = float(output[\"scores\"][0])\n",
    "        except Exception as e:\n",
    "            score = float(\"nan\")\n",
    "        records.append({\n",
    "            \"model\": mname,\n",
    "            \"file\": rec[\"file\"],\n",
    "            \"qe_score\": score\n",
    "        })\n",
    "\n",
    "qe_df = pd.DataFrame(records)\n",
    "print(qe_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac01f47",
   "metadata": {},
   "source": [
    "## 8. Aggregate Scores & Prepare for Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f265279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map model names to hypothesis labels and pivot\n",
    "qe_df[\"hypothesis\"] = qe_df[\"model\"].map(labels)\n",
    "wide = qe_df.pivot_table(index=\"file\", columns=\"hypothesis\", values=\"qe_score\")\n",
    "\n",
    "# Persist scores\n",
    "scores_csv = os.path.join(BASE_DIR, \"qe_scores_per_file.csv\")\n",
    "qe_df.to_csv(scores_csv, index=False)\n",
    "print(\"Saved per-file scores:\", scores_csv)\n",
    "\n",
    "wide_csv = os.path.join(BASE_DIR, \"qe_scores_wide.csv\")\n",
    "wide.to_csv(wide_csv)\n",
    "print(\"Saved wide scores:\", wide_csv)\n",
    "\n",
    "wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b17527",
   "metadata": {},
   "source": [
    "## 9. Statistical Evaluation (Paired t‑tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a918982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform paired t-tests between all pairs of hypotheses on matched files.\n",
    "# Interpretation: tests whether the mean QE score differs between two hypotheses across the same file set.\n",
    "\n",
    "results = []\n",
    "cols = [c for c in wide.columns if c is not None]\n",
    "for a, b in itertools.combinations(cols, 2):\n",
    "    # Drop rows where either hypothesis is NaN to keep pairs matched\n",
    "    ab = wide[[a, b]].dropna()\n",
    "    if len(ab) < 2:\n",
    "        t_stat, p_val = float(\"nan\"), float(\"nan\")\n",
    "    else:\n",
    "        t_stat, p_val = stats.ttest_rel(ab[a], ab[b])\n",
    "    results.append({\"Hypothesis 1\": a, \"Hypothesis 2\": b, \"t-statistic\": t_stat, \"p-value\": p_val, \"n\": len(ab)})\n",
    "\n",
    "stats_df = pd.DataFrame(results).sort_values([\"Hypothesis 1\", \"Hypothesis 2\"]).reset_index(drop=True)\n",
    "\n",
    "stats_xlsx = os.path.join(BASE_DIR, \"paired_ttest_results.xlsx\")\n",
    "stats_df.to_excel(stats_xlsx, index=False)\n",
    "print(\"Paired t-test results saved to:\", stats_xlsx)\n",
    "\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745599c",
   "metadata": {},
   "source": [
    "## 10. Methods Summary\n",
    "\n",
    "- **Parsing:** Each `.txt` is split into *Source* and *Output* using the first occurrence of `Output:` (case-insensitive variant also supported).\n",
    "- **Hypotheses:** For each AI model folder, all sources are concatenated into `src.txt` and all corresponding model outputs into `hypX.txt` (where `X` is the hypothesis index).\n",
    "- **Quality Estimation:** Sentence-level, reference-free **COMET QE** model (`wmt21-comet-qe-mqm`) is used to assign a score to each (source, hypothesis) pair.\n",
    "- **Statistical Testing:** Two-tailed **paired t‑tests** compare per-file QE scores across hypotheses (matched on the same file set)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
